{
 "cells": [
  {
   "cell_type": "raw",
   "id": "60ba7368",
   "metadata": {},
   "source": [
    "In this Notebook we have input text file(Hungarain Corpus) with  long length for lines, what we do:\n",
    "    - read this text line by line and do normlization for it and then break lines by spesfic length \n",
    "    - save results as text file (target make file like brown corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cb9b5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e33c74a",
   "metadata": {},
   "source": [
    "#  1:  Read a File Line by Line using for loop and list comprehension\n",
    "## 1.0 : Vitulize data text using Pandas befor process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aaac1dca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Avagy: mire megy√ºnk egy keleti kult√∫ra eszk√∂ze...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gy√∂rk√∂s csal√°di n√©v egy sz√°zas sk√°l√°n 24 ponto...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A fenti karakterekb≈ël √∂sszerakhat√≥ magyar szav...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ha megvizsg√°ljuk a Gy√∂rk√∂s Attila n√©v karakter...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    1    2    3    4    5  \\\n",
       "0  Avagy: mire megy√ºnk egy keleti kult√∫ra eszk√∂ze...  NaN  NaN  NaN  NaN  NaN   \n",
       "1                                                NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "2  Gy√∂rk√∂s csal√°di n√©v egy sz√°zas sk√°l√°n 24 ponto...  NaN  NaN  NaN  NaN  NaN   \n",
       "3  A fenti karakterekb≈ël √∂sszerakhat√≥ magyar szav...  NaN  NaN  NaN  NaN  NaN   \n",
       "4  Ha megvizsg√°ljuk a Gy√∂rk√∂s Attila n√©v karakter...  NaN  NaN  NaN  NaN  NaN   \n",
       "\n",
       "     6    7    8    9   10   11   12  \n",
       "0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "1  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "2  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "3  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "4  NaN  NaN  NaN  NaN  NaN  NaN  NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '/home/ngyongyossy/mohammad/Data/Hu_corpus/MFileSiplite/data/'\n",
    "fname= 'split_38.txt'\n",
    "df = pd.read_fwf(f'{path}Input/{fname}', header=None)\n",
    "df.rename(columns={0: \"text\"}, inplace=True)\n",
    "# del df[1] \n",
    "# del df[2]\n",
    "# del df[3]\n",
    "# del df[4]\n",
    "# del df[5]\n",
    "# del df[6]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "189e49ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4749546</td>\n",
       "      <td>202482</td>\n",
       "      <td>121119</td>\n",
       "      <td>59108</td>\n",
       "      <td>67832</td>\n",
       "      <td>65834</td>\n",
       "      <td>63900</td>\n",
       "      <td>62019</td>\n",
       "      <td>52809</td>\n",
       "      <td>60610</td>\n",
       "      <td>59733</td>\n",
       "      <td>58721</td>\n",
       "      <td>57120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>3836617</td>\n",
       "      <td>198545</td>\n",
       "      <td>119223</td>\n",
       "      <td>126</td>\n",
       "      <td>65865</td>\n",
       "      <td>63963</td>\n",
       "      <td>62056</td>\n",
       "      <td>52318</td>\n",
       "      <td>126</td>\n",
       "      <td>35373</td>\n",
       "      <td>44660</td>\n",
       "      <td>56442</td>\n",
       "      <td>1797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Felhaszn√°l√°si felt√©telek</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>e</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>e</td>\n",
       "      <td>hogy</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>9455</td>\n",
       "      <td>607</td>\n",
       "      <td>305</td>\n",
       "      <td>5676</td>\n",
       "      <td>132</td>\n",
       "      <td>131</td>\n",
       "      <td>117</td>\n",
       "      <td>106</td>\n",
       "      <td>5008</td>\n",
       "      <td>230</td>\n",
       "      <td>111</td>\n",
       "      <td>106</td>\n",
       "      <td>1876</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            text       1       2      3      4      5      6  \\\n",
       "count                    4749546  202482  121119  59108  67832  65834  63900   \n",
       "unique                   3836617  198545  119223    126  65865  63963  62056   \n",
       "top     Felhaszn√°l√°si felt√©telek       .       .      e      .      .      .   \n",
       "freq                        9455     607     305   5676    132    131    117   \n",
       "\n",
       "            7      8      9     10     11     12  \n",
       "count   62019  52809  60610  59733  58721  57120  \n",
       "unique  52318    126  35373  44660  56442   1797  \n",
       "top         .      e   hogy      .      .      a  \n",
       "freq      106   5008    230    111    106   1876  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a3cb015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000001 entries, 0 to 5000000\n",
      "Data columns (total 13 columns):\n",
      "text    object\n",
      "1       object\n",
      "2       object\n",
      "3       object\n",
      "4       object\n",
      "5       object\n",
      "6       object\n",
      "7       object\n",
      "8       object\n",
      "9       object\n",
      "10      object\n",
      "11      object\n",
      "12      object\n",
      "dtypes: object(13)\n",
      "memory usage: 495.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eed99be3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Avagy: mire megy√ºnk egy keleti kult√∫ra eszk√∂zeivel annak szellemis√©ge n√©lk√ºl?'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4126ed2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avagy: mire megy√ºnk egy keleti kult√∫ra eszk√∂zeivel annak szellemis√©ge n√©lk√ºl?\n"
     ]
    }
   ],
   "source": [
    "# removing the new line characters\n",
    "with open(f'{path}Input/{fname}', 'r', encoding='utf-8') as f:\n",
    "    lines = [line.rstrip() for line in f]\n",
    "print(lines[0]) \n",
    "# [str1,str2,....., str_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "801084e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'vazonosito, 2017 Augusztus 13'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08392c71",
   "metadata": {},
   "source": [
    "# 1.1 : Normlization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7c888c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normlized_text(line):\n",
    "    result1 = re.sub(r'[ ‚ñ∫ (  )  ‚Ä¢  ¬©  @  ‚Ä¶  ~  üòÄ  >  <  `  !  _ { } + * ]', ' ', line)\n",
    "#     Q: url (remove word after ??!!) not matter if you remove it \n",
    "    return re.sub(r'https?://\\S+', '', result1)\n",
    "# str ---> str "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "279fe59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_lists = []\n",
    "def sents_to_words(line):\n",
    "        normlized_line = normlized_text(line)\n",
    "#         print(normlized_line)\n",
    "        words = normlized_line.split()\n",
    "        words_lists.append(words)\n",
    "#         return ()\n",
    "# line: str --> words[]:list\n",
    "# words_lists[words1['w1','w2',....,'w_n'],words2['w1','w2',....,'w_n'],words3['w1','w2',....,'w_n'] ....words_n['w1','w2',....,'w_n']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4c02fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(sents_to_words('Az iskolai erÿ•‚Äòszakrÿ£¬≥l https://www.geeksforgeeks.org/read-a-file-line-by-line-in-python/ nyilatkozÿ£¬≥knak csak a fele ÿ£¬©rzi, hogy gyermeke biztonsÿ£ÿågban van az iskolÿ£ÿåban.')) # ,lines[-1])\n",
    "# test \n",
    "# sents_to_words(lines[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36261bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call fun to normlize & convert to words lists \n",
    "for line in lines:\n",
    "    normlized_line = sents_to_words(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b29f8f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000001,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = len(words_lists) , # see the length befor removing empty lines \n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cef89d14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4749546"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove empty list if exists caused by empty line e.g : [[1, 2], [1], [], [1, 2, 3, 4]] ==> [[1, 2], [1], [1, 2, 3, 4]]\n",
    "words_lists = [x for x in words_lists if x]\n",
    "b = len(words_lists)  # see the length after removing empty lines \n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a09e9b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed Empty Lines :  250455\n"
     ]
    }
   ],
   "source": [
    "print('Removed Empty Lines : ', a[0]-b)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ac63634c",
   "metadata": {},
   "source": [
    "# 1.2 : Issue removing word after url if  there is no space after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "749a7ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Belfÿ£¬∂ld -  hÿ£¬≠rei   Elÿ£ gedetlenek az emberek a kÿ£¬∂zoktatÿ£ÿåssal?\n"
     ]
    }
   ],
   "source": [
    "# test normlize function with Hu\n",
    "print(normlized_text('Belfÿ£¬∂ld - https://www.geeksforgeeks.org/read-a-file-line-by-line-in-python/Magyarorszÿ£ÿåg hÿ£\\xadrei > Elÿ£¬©gedetlenek az emberek a kÿ£¬∂zoktatÿ£ÿåssal?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd25b148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Fulton County Grand Jury said Friday an investigation of Atlanta's recent primary election produced \"no evidence\" that any irregularities took place.\n"
     ]
    }
   ],
   "source": [
    "# test normlize function with En\n",
    "print(normlized_text('https://www.geeksforgeeks.org/read-a-file-line-by-line-in-python/The Fulton County Grand Jury said Friday an investigation of Atlanta\\'s recent primary election produced \"no evidence\" that any irregularities took place.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77f30e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avagy:\n",
      "mire\n",
      "megy√ºnk\n",
      "egy\n",
      "keleti\n",
      "kult√∫ra\n",
      "eszk√∂zeivel\n",
      "annak\n",
      "szellemis√©ge\n",
      "n√©lk√ºl?\n"
     ]
    }
   ],
   "source": [
    "# words_lists[words1[W1,W2,....,W_n],words2 [W1,W2,....,W_n],...,words_n[W1,W2,....,W_n]]   : test one elment from word list \n",
    "for words in words_lists[0]:\n",
    "    print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7bd0746f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from   [words1[W1,W2,....,W_n],words2 [W1,W2,....,W_n],...,words_n[W1,W2,....,W_n]]\n",
    "# to     flat_list[W1,W2,....,W_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "36261cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Her we have one list contians all words \n",
    "# if you have limited memoey you have to find a way like sipliting to chunk (in case local machine with 8GB there is limitation only with 1 milleion )\n",
    "# flat_list_chunk1 = [word for sublist in words_lists[:1000000] for word in sublist]\n",
    "# flat_list_chunk2 = [word for sublist in words_lists[1000000:2000000] for word in sublist]\n",
    "# flat_list_chunk3 = [word for sublist in words_lists[2000000:3000000] for word in sublist]\n",
    "# flat_list_chunk4 = [word for sublist in words_lists[3000000:4000000] for word in sublist]\n",
    "# flat_list_chunk5 = [word for sublist in words_lists[2000000:3000000] for word in sublist]\n",
    "# CONCATENATE THEM\n",
    "# flat_list = flat_list_chunk1 + flat_list_chunk2 + flat_list_chunk3 + flat_list_chunk4 +flat_list_chunk5\n",
    "flat_list = [word for sublist in words_lists for word in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e35e0253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'13'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_list[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0725012b",
   "metadata": {},
   "source": [
    "# 2: Break a words of list into chunks of size N using List comprehension "
   ]
  },
  {
   "cell_type": "raw",
   "id": "0924334b",
   "metadata": {},
   "source": [
    "flat_list[W1,W2,....,W_n]  -->  final[[w1,w2,...,w10 or w11],[w12,..., w20],   [...]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dde42127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of resulting lines  9\n",
      "['k√©tszer', 'ugyanabba', 'a', 'foly√≥ba\"', '-', 'mondta', 'H√©rakleitosz.', 'vazonosito,', '2017']\n"
     ]
    }
   ],
   "source": [
    "# We choose random length for line \n",
    "n = random.randint(8, 9)\n",
    "print('The length of resulting lines ',n)\n",
    "# using list comprehension\n",
    "# final = [flat_list[i * n:(i + 1) * n] for i in range((len(flat_list) + n - 1) // n )]\n",
    "final = [flat_list[i:i + n] for i in range(0, len(flat_list), n)]     # alternative  to line above \n",
    "print (final[-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c49c5a",
   "metadata": {},
   "source": [
    "# 2.1 : Save results to txt file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "be23b235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Expacted number of liens  11438382\n"
     ]
    }
   ],
   "source": [
    "print('The Expacted number of liens ',len(final))\n",
    "with open(f'{path}out/out_{fname}','w' ,encoding='utf-8') as file:\n",
    "    for items in final:\n",
    "        for item in items:        \n",
    "            file.write(f\"{item} \")\n",
    "        file.write(\"\\n\")\n",
    "file.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0d31355d",
   "metadata": {},
   "source": [
    "# 2.2 : Vitulize text file after processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "81dbb178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Avagy: mire megy√ºnk egy keleti kult√∫ra eszk√∂ze...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n√©lk√ºl? Gy√∂rk√∂s csal√°di n√©v egy sz√°zas sk√°l√°n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gyakoris√°g√∫. Attila keresztn√©v gyakoris√°ga: A ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n√©v k√∂z√© tartozik. Els≈ë n√©vk√©nt kb 1.4384% vis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a nevet sz√°znegyvenh√°romezer-nyolcsz√°znegyvene...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  Avagy: mire megy√ºnk egy keleti kult√∫ra eszk√∂ze...\n",
       "1  n√©lk√ºl? Gy√∂rk√∂s csal√°di n√©v egy sz√°zas sk√°l√°n ...\n",
       "2  gyakoris√°g√∫. Attila keresztn√©v gyakoris√°ga: A ...\n",
       "3  n√©v k√∂z√© tartozik. Els≈ë n√©vk√©nt kb 1.4384% vis...\n",
       "4  a nevet sz√°znegyvenh√°romezer-nyolcsz√°znegyvene..."
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# path = 'out_split_1.txt'\n",
    "df = pd.read_fwf(f'{path}out/out_{fname}', header=None)\n",
    "df.rename(columns={0: \"text\"}, inplace=True)\n",
    "# del df[1] \n",
    "# del df[2]\n",
    "# del df[3]\n",
    "# del df[4]\n",
    "# del df[5]\n",
    "# del df[6]\n",
    "# del df[7]\n",
    "# del df[8]\n",
    "# del df[9]\n",
    "# del df[10]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1e5cdd34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>11438382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>11093227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>K√ºld√©s e-mailbenBlogThis Megoszt√°s a Twitteren...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text\n",
       "count                                            11438382\n",
       "unique                                           11093227\n",
       "top     K√ºld√©s e-mailbenBlogThis Megoszt√°s a Twitteren...\n",
       "freq                                                  307"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "50d686b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11438382 entries, 0 to 11438381\n",
      "Data columns (total 1 columns):\n",
      "text    object\n",
      "dtypes: object(1)\n",
      "memory usage: 87.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "85b21d08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Avagy: mire megy√ºnk egy keleti kult√∫ra eszk√∂zeivel annak szellemis√©ge'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'] [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "60c3e601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('newnewnew.txt' ,encoding='utf-8') as f:\n",
    "#     lines = [line for line in f]\n",
    "# print(len(lines),'\\n')\n",
    "# # removing the new line characters\n",
    "# with open('out_split_1.txt.txt' ,encoding='utf-8') as f:\n",
    "#     lines = [line.rstrip() for line in f]\n",
    "# print(lines)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
