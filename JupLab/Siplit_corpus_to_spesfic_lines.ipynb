{
 "cells": [
  {
   "cell_type": "raw",
   "id": "60ba7368",
   "metadata": {},
   "source": [
    "In this Notebook we have input text file(Hungarain Corpus) with  long length for lines, what we do:\n",
    "    - read this text line by line and do normlization for it and then break lines by spesfic length \n",
    "    - save results as text file (target make file like brown corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cb9b5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e33c74a",
   "metadata": {},
   "source": [
    "#  1:  Read a File Line by Line using for loop and list comprehension\n",
    "## 1.0 : Vitulize data text using Pandas befor process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aaac1dca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A magyarok k√∂zel harmada bevallottan rendszert...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A GfK Hung√°ria k√©t√©vente vizsg√°lja a magyarors...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A t√≠z legsz√≠vesebben fogyasztott √©lelmiszer k√∂...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A megk√©rdezettek 57 sz√°zal√©ka - saj√°t bevall√°s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Szerz≈ëi jogok</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    1    2    3    4    5  \\\n",
       "0  A magyarok k√∂zel harmada bevallottan rendszert...  NaN  NaN  NaN  NaN  NaN   \n",
       "1  A GfK Hung√°ria k√©t√©vente vizsg√°lja a magyarors...  NaN  NaN  NaN  NaN  NaN   \n",
       "2  A t√≠z legsz√≠vesebben fogyasztott √©lelmiszer k√∂...  NaN  NaN  NaN  NaN  NaN   \n",
       "3  A megk√©rdezettek 57 sz√°zal√©ka - saj√°t bevall√°s...  NaN  NaN  NaN  NaN  NaN   \n",
       "4                                      Szerz≈ëi jogok  NaN  NaN  NaN  NaN  NaN   \n",
       "\n",
       "     6    7    8    9   10   11   12   13   14   15  \n",
       "0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "1  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "2  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "3  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "4  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '/home/ngyongyossy/mohammad/Data/Hu_corpus/MFileSiplite/data/'\n",
    "fname= 'split_30.txt'\n",
    "df = pd.read_fwf(f'{path}Input/{fname}', header=None)\n",
    "df.rename(columns={0: \"text\"}, inplace=True)\n",
    "# del df[1] \n",
    "# del df[2]\n",
    "# del df[3]\n",
    "# del df[4]\n",
    "# del df[5]\n",
    "# del df[6]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "189e49ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4800009</td>\n",
       "      <td>86665</td>\n",
       "      <td>68183</td>\n",
       "      <td>78378</td>\n",
       "      <td>77198</td>\n",
       "      <td>76005</td>\n",
       "      <td>72787</td>\n",
       "      <td>71075</td>\n",
       "      <td>70397</td>\n",
       "      <td>68706</td>\n",
       "      <td>67864</td>\n",
       "      <td>65892</td>\n",
       "      <td>63927</td>\n",
       "      <td>55053</td>\n",
       "      <td>63215</td>\n",
       "      <td>61909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>3840419</td>\n",
       "      <td>85466</td>\n",
       "      <td>124</td>\n",
       "      <td>42714</td>\n",
       "      <td>42311</td>\n",
       "      <td>74787</td>\n",
       "      <td>67767</td>\n",
       "      <td>9804</td>\n",
       "      <td>65685</td>\n",
       "      <td>24202</td>\n",
       "      <td>66397</td>\n",
       "      <td>64475</td>\n",
       "      <td>1835</td>\n",
       "      <td>122</td>\n",
       "      <td>56716</td>\n",
       "      <td>60905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Felhaszn√°l√°si felt√©telek</td>\n",
       "      <td>.</td>\n",
       "      <td>e</td>\n",
       "      <td>hogy</td>\n",
       "      <td>hogy</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>a</td>\n",
       "      <td>.</td>\n",
       "      <td>az</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>a</td>\n",
       "      <td>e</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>9047</td>\n",
       "      <td>168</td>\n",
       "      <td>6646</td>\n",
       "      <td>272</td>\n",
       "      <td>265</td>\n",
       "      <td>154</td>\n",
       "      <td>137</td>\n",
       "      <td>660</td>\n",
       "      <td>100</td>\n",
       "      <td>256</td>\n",
       "      <td>96</td>\n",
       "      <td>116</td>\n",
       "      <td>2147</td>\n",
       "      <td>5287</td>\n",
       "      <td>99</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            text      1      2      3      4      5      6  \\\n",
       "count                    4800009  86665  68183  78378  77198  76005  72787   \n",
       "unique                   3840419  85466    124  42714  42311  74787  67767   \n",
       "top     Felhaszn√°l√°si felt√©telek      .      e   hogy   hogy      .      .   \n",
       "freq                        9047    168   6646    272    265    154    137   \n",
       "\n",
       "            7      8      9     10     11     12     13     14     15  \n",
       "count   71075  70397  68706  67864  65892  63927  55053  63215  61909  \n",
       "unique   9804  65685  24202  66397  64475   1835    122  56716  60905  \n",
       "top         a      .     az      .      .      a      e      .      .  \n",
       "freq      660    100    256     96    116   2147   5287     99     89  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a3cb015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000001 entries, 0 to 5000000\n",
      "Data columns (total 16 columns):\n",
      "text    object\n",
      "1       object\n",
      "2       object\n",
      "3       object\n",
      "4       object\n",
      "5       object\n",
      "6       object\n",
      "7       object\n",
      "8       object\n",
      "9       object\n",
      "10      object\n",
      "11      object\n",
      "12      object\n",
      "13      object\n",
      "14      object\n",
      "15      object\n",
      "dtypes: object(16)\n",
      "memory usage: 610.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eed99be3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A magyarok k√∂zel harmada bevallottan rendszertelen√ºl √©tkezik, √©s jelent≈ësen megn≈ëtt azoknak az ar√°nya, akiknek a f≈ë √©tkez√©se az eb√©d helyett a vacsora lett - der√ºl ki a GfK Hung√°ria Piackutat√≥ Int√©zet √©tkez√©si szok√°sokat vizsg√°l√≥ tanulm√°ny√°nak idei adataib√≥l.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4126ed2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A magyarok k√∂zel harmada bevallottan rendszertelen√ºl √©tkezik, √©s jelent≈ësen megn≈ëtt azoknak az ar√°nya, akiknek a f≈ë √©tkez√©se az eb√©d helyett a vacsora lett - der√ºl ki a GfK Hung√°ria Piackutat√≥ Int√©zet √©tkez√©si szok√°sokat vizsg√°l√≥ tanulm√°ny√°nak idei adataib√≥l.\n"
     ]
    }
   ],
   "source": [
    "# removing the new line characters\n",
    "with open(f'{path}Input/{fname}', 'r', encoding='utf-8') as f:\n",
    "    lines = [line.rstrip() for line in f]\n",
    "print(lines[0]) \n",
    "# [str1,str2,....., str_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "801084e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Epil√≥gus: a nemzet √©s annak vall√°sa [pdf, 207.6k]'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08392c71",
   "metadata": {},
   "source": [
    "# 1.1 : Normlization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7c888c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normlized_text(line):\n",
    "    result1 = re.sub(r'[ ‚ñ∫ (  )  ‚Ä¢  ¬©  @  ‚Ä¶  ~  üòÄ  >  <  `  !  _ { } + * ]', ' ', line)\n",
    "#     Q: url (remove word after ??!!) not matter if you remove it \n",
    "    return re.sub(r'https?://\\S+', '', result1)\n",
    "# str ---> str "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "279fe59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_lists = []\n",
    "def sents_to_words(line):\n",
    "        normlized_line = normlized_text(line)\n",
    "#         print(normlized_line)\n",
    "        words = normlized_line.split()\n",
    "        words_lists.append(words)\n",
    "#         return ()\n",
    "# line: str --> words[]:list\n",
    "# words_lists[words1['w1','w2',....,'w_n'],words2['w1','w2',....,'w_n'],words3['w1','w2',....,'w_n'] ....words_n['w1','w2',....,'w_n']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4c02fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(sents_to_words('Az iskolai erÿ•‚Äòszakrÿ£¬≥l https://www.geeksforgeeks.org/read-a-file-line-by-line-in-python/ nyilatkozÿ£¬≥knak csak a fele ÿ£¬©rzi, hogy gyermeke biztonsÿ£ÿågban van az iskolÿ£ÿåban.')) # ,lines[-1])\n",
    "# test \n",
    "# sents_to_words(lines[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36261bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call fun to normlize & convert to words lists \n",
    "for line in lines:\n",
    "    normlized_line = sents_to_words(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b29f8f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000001,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = len(words_lists) , # see the length befor removing empty lines \n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cef89d14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4800009"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove empty list if exists caused by empty line e.g : [[1, 2], [1], [], [1, 2, 3, 4]] ==> [[1, 2], [1], [1, 2, 3, 4]]\n",
    "words_lists = [x for x in words_lists if x]\n",
    "b = len(words_lists)  # see the length after removing empty lines \n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a09e9b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed Empty Lines :  199992\n"
     ]
    }
   ],
   "source": [
    "print('Removed Empty Lines : ', a[0]-b)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ac63634c",
   "metadata": {},
   "source": [
    "# 1.2 : Issue removing word after url if  there is no space after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "749a7ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Belfÿ£¬∂ld -  hÿ£¬≠rei   Elÿ£ gedetlenek az emberek a kÿ£¬∂zoktatÿ£ÿåssal?\n"
     ]
    }
   ],
   "source": [
    "# test normlize function with Hu\n",
    "print(normlized_text('Belfÿ£¬∂ld - https://www.geeksforgeeks.org/read-a-file-line-by-line-in-python/Magyarorszÿ£ÿåg hÿ£\\xadrei > Elÿ£¬©gedetlenek az emberek a kÿ£¬∂zoktatÿ£ÿåssal?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd25b148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Fulton County Grand Jury said Friday an investigation of Atlanta's recent primary election produced \"no evidence\" that any irregularities took place.\n"
     ]
    }
   ],
   "source": [
    "# test normlize function with En\n",
    "print(normlized_text('https://www.geeksforgeeks.org/read-a-file-line-by-line-in-python/The Fulton County Grand Jury said Friday an investigation of Atlanta\\'s recent primary election produced \"no evidence\" that any irregularities took place.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77f30e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "magyarok\n",
      "k√∂zel\n",
      "harmada\n",
      "bevallottan\n",
      "rendszertelen√ºl\n",
      "√©tkezik,\n",
      "√©s\n",
      "jelent≈ësen\n",
      "megn≈ëtt\n",
      "azoknak\n",
      "az\n",
      "ar√°nya,\n",
      "akiknek\n",
      "a\n",
      "f≈ë\n",
      "√©tkez√©se\n",
      "az\n",
      "eb√©d\n",
      "helyett\n",
      "a\n",
      "vacsora\n",
      "lett\n",
      "-\n",
      "der√ºl\n",
      "ki\n",
      "a\n",
      "GfK\n",
      "Hung√°ria\n",
      "Piackutat√≥\n",
      "Int√©zet\n",
      "√©tkez√©si\n",
      "szok√°sokat\n",
      "vizsg√°l√≥\n",
      "tanulm√°ny√°nak\n",
      "idei\n",
      "adataib√≥l.\n"
     ]
    }
   ],
   "source": [
    "# words_lists[words1[W1,W2,....,W_n],words2 [W1,W2,....,W_n],...,words_n[W1,W2,....,W_n]]   : test one elment from word list \n",
    "for words in words_lists[0]:\n",
    "    print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7bd0746f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from   [words1[W1,W2,....,W_n],words2 [W1,W2,....,W_n],...,words_n[W1,W2,....,W_n]]\n",
    "# to     flat_list[W1,W2,....,W_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "36261cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Her we have one list contians all words \n",
    "# if you have limited memoey you have to find a way like sipliting to chunk (in case local machine with 8GB there is limitation only with 1 milleion )\n",
    "# flat_list_chunk1 = [word for sublist in words_lists[:1000000] for word in sublist]\n",
    "# flat_list_chunk2 = [word for sublist in words_lists[1000000:2000000] for word in sublist]\n",
    "# flat_list_chunk3 = [word for sublist in words_lists[2000000:3000000] for word in sublist]\n",
    "# flat_list_chunk4 = [word for sublist in words_lists[3000000:4000000] for word in sublist]\n",
    "# flat_list_chunk5 = [word for sublist in words_lists[2000000:3000000] for word in sublist]\n",
    "# CONCATENATE THEM\n",
    "# flat_list = flat_list_chunk1 + flat_list_chunk2 + flat_list_chunk3 + flat_list_chunk4 +flat_list_chunk5\n",
    "flat_list = [word for sublist in words_lists for word in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e35e0253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'207.6k]'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_list[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0725012b",
   "metadata": {},
   "source": [
    "# 2: Break a words of list into chunks of size N using List comprehension "
   ]
  },
  {
   "cell_type": "raw",
   "id": "0924334b",
   "metadata": {},
   "source": [
    "flat_list[W1,W2,....,W_n]  -->  final[[w1,w2,...,w10 or w11],[w12,..., w20],   [...]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dde42127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of resulting lines  9\n",
      "['lehets√©ges-e', 'forradalom?', '‚ÄûA', 'gyertyam√°rt√≥k', 'k√∂zt√°rsas√°ga‚Äù', 'Epil√≥gus:', 'a', 'nemzet', '√©s']\n"
     ]
    }
   ],
   "source": [
    "# We choose random length for line \n",
    "n = random.randint(8, 9)\n",
    "print('The length of resulting lines ',n)\n",
    "# using list comprehension\n",
    "# final = [flat_list[i * n:(i + 1) * n] for i in range((len(flat_list) + n - 1) // n )]\n",
    "final = [flat_list[i:i + n] for i in range(0, len(flat_list), n)]     # alternative  to line above \n",
    "print (final[-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c49c5a",
   "metadata": {},
   "source": [
    "# 2.1 : Save results to txt file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "be23b235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Expacted number of liens  11620531\n"
     ]
    }
   ],
   "source": [
    "print('The Expacted number of liens ',len(final))\n",
    "with open(f'{path}out/out_{fname}','w' ,encoding='utf-8') as file:\n",
    "    for items in final:\n",
    "        for item in items:        \n",
    "            file.write(f\"{item} \")\n",
    "        file.write(\"\\n\")\n",
    "file.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0d31355d",
   "metadata": {},
   "source": [
    "# 2.2 : Vitulize text file after processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "81dbb178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A magyarok k√∂zel harmada bevallottan rendszert...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>megn≈ëtt azoknak az ar√°nya, akiknek a f≈ë √©tkez√©...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eb√©d helyett a vacsora lett - der√ºl ki a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GfK Hung√°ria Piackutat√≥ Int√©zet √©tkez√©si szok√°...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adataib√≥l. A GfK Hung√°ria k√©t√©vente vizsg√°lja ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  A magyarok k√∂zel harmada bevallottan rendszert...\n",
       "1  megn≈ëtt azoknak az ar√°nya, akiknek a f≈ë √©tkez√©...\n",
       "2           eb√©d helyett a vacsora lett - der√ºl ki a\n",
       "3  GfK Hung√°ria Piackutat√≥ Int√©zet √©tkez√©si szok√°...\n",
       "4  adataib√≥l. A GfK Hung√°ria k√©t√©vente vizsg√°lja ..."
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# path = 'out_split_1.txt'\n",
    "df = pd.read_fwf(f'{path}out/out_{fname}', header=None)\n",
    "df.rename(columns={0: \"text\"}, inplace=True)\n",
    "# del df[1] \n",
    "# del df[2]\n",
    "# del df[3]\n",
    "# del df[4]\n",
    "# del df[5]\n",
    "# del df[6]\n",
    "# del df[7]\n",
    "# del df[8]\n",
    "# del df[9]\n",
    "# del df[10]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1e5cdd34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>11620531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>11234922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>J E G Y Z ≈ê K √ñ N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     text\n",
       "count            11620531\n",
       "unique           11234922\n",
       "top     J E G Y Z ≈ê K √ñ N\n",
       "freq                  368"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "50d686b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11620531 entries, 0 to 11620530\n",
      "Data columns (total 1 columns):\n",
      "text    object\n",
      "dtypes: object(1)\n",
      "memory usage: 88.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "85b21d08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A magyarok k√∂zel harmada bevallottan rendszertelen√ºl √©tkezik, √©s jelent≈ësen'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'] [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "60c3e601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('newnewnew.txt' ,encoding='utf-8') as f:\n",
    "#     lines = [line for line in f]\n",
    "# print(len(lines),'\\n')\n",
    "# # removing the new line characters\n",
    "# with open('out_split_1.txt.txt' ,encoding='utf-8') as f:\n",
    "#     lines = [line.rstrip() for line in f]\n",
    "# print(lines)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
